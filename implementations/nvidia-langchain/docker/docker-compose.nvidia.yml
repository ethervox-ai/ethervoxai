version: '3.8'

services:
  # Main EthervoxAI NVIDIA service
  ethervoxai-nvidia:
    build:
      context: ..
      dockerfile: docker/Dockerfile.nvidia
    container_name: ethervoxai-nvidia-main
    runtime: nvidia
    restart: unless-stopped
    
    environment:
      # NVIDIA settings
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0,1,2,3
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      
      # Application settings
      - ETHERVOX_LOG_LEVEL=INFO
      - ETHERVOX_MODEL_CACHE=/app/cache
      - ETHERVOX_MODEL_REPOSITORY=/app/models
      - ETHERVOX_CONFIG_PATH=/app/configs/nvidia_stack.yaml
      
      # Performance settings
      - TORCH_CUDA_ARCH_LIST="7.5;8.0;8.6;8.9;9.0"
      - CUDA_LAUNCH_BLOCKING=0
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
      
      # Security settings
      - ETHERVOX_SECURITY_LEVEL=standard
      - ETHERVOX_COMPLIANCE_MODE=gdpr
      
    volumes:
      # Model storage
      - nvidia_models:/app/models
      - nvidia_cache:/app/cache
      - nvidia_logs:/app/logs
      
      # Configuration
      - ./configs:/app/configs:ro
      
      # Optional: Host model directory
      # - /host/path/to/models:/app/models
      
    ports:
      - "8000:8000"  # HTTP API
      - "8001:8001"  # gRPC API
      - "8002:8002"  # Metrics endpoint
      
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
        limits:
          memory: 32G
          cpus: '16'
          
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
      
    networks:
      - ethervox-network

  # NVIDIA Triton Inference Server
  triton-server:
    image: nvcr.io/nvidia/tritonserver:23.10-py3
    container_name: ethervoxai-triton
    runtime: nvidia
    restart: unless-stopped
    
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0,1,2,3
      
    command: >
      tritonserver
      --model-repository=/models
      --grpc-port=8001
      --http-port=8000
      --metrics-port=8002
      --log-verbose=1
      --strict-model-config=false
      --strict-readiness=false
      --allow-http=true
      --allow-grpc=true
      --allow-metrics=true
      
    volumes:
      - triton_models:/models
      - triton_cache:/cache
      
    ports:
      - "8100:8000"  # HTTP
      - "8101:8001"  # gRPC  
      - "8102:8002"  # Metrics
      
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
        limits:
          memory: 16G
          cpus: '8'
          
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v2/health/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
      
    networks:
      - ethervox-network

  # Vector Database (ChromaDB with GPU support)
  chroma-db:
    image: chromadb/chroma:latest
    container_name: ethervoxai-chroma
    restart: unless-stopped
    
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
      - CHROMA_SERVER_CORS_ALLOW_ORIGINS=["*"]
      
    volumes:
      - chroma_data:/chroma/chroma
      
    ports:
      - "8200:8000"
      
    networks:
      - ethervox-network

  # Redis for caching and session management  
  redis:
    image: redis:7.2-alpine
    container_name: ethervoxai-redis
    restart: unless-stopped
    
    command: redis-server --appendonly yes --maxmemory 1gb --maxmemory-policy allkeys-lru
    
    volumes:
      - redis_data:/data
      
    ports:
      - "6379:6379"
      
    networks:
      - ethervox-network

  # Prometheus for monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: ethervoxai-prometheus
    restart: unless-stopped
    
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
      
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
      
    ports:
      - "9090:9090"
      
    networks:
      - ethervox-network

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: ethervoxai-grafana
    restart: unless-stopped
    
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=ethervox123
      - GF_USERS_ALLOW_SIGN_UP=false
      
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
      
    ports:
      - "3000:3000"
      
    networks:
      - ethervox-network

  # NGINX reverse proxy and load balancer
  nginx:
    image: nginx:alpine
    container_name: ethervoxai-nginx
    restart: unless-stopped
    
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      
    ports:
      - "80:80"
      - "443:443"
      
    depends_on:
      - ethervoxai-nvidia
      - triton-server
      
    networks:
      - ethervox-network

volumes:
  # NVIDIA service volumes
  nvidia_models:
    driver: local
  nvidia_cache:
    driver: local
  nvidia_logs:
    driver: local
    
  # Triton volumes
  triton_models:
    driver: local
  triton_cache:
    driver: local
    
  # Database volumes
  chroma_data:
    driver: local
  redis_data:
    driver: local
    
  # Monitoring volumes
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  ethervox-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# Development override
# Use: docker-compose -f docker-compose.nvidia.yml -f docker-compose.dev.yml up
---
version: '3.8'

# Development overrides
services:
  ethervoxai-nvidia:
    build:
      target: builder  # Use development build
    environment:
      - ETHERVOX_LOG_LEVEL=DEBUG
      - ETHERVOX_DEV_MODE=true
    volumes:
      - ../src:/app/src:ro  # Mount source for development
      - ../examples:/app/examples:ro
    command: ["python3", "-m", "src.api.dev_server"]

  # Development tools
  jupyter:
    build:
      context: ..
      dockerfile: docker/Dockerfile.nvidia
    container_name: ethervoxai-jupyter
    runtime: nvidia
    
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - JUPYTER_ENABLE_LAB=yes
      
    command: >
      jupyter lab
      --ip=0.0.0.0
      --port=8888
      --no-browser
      --allow-root
      --NotebookApp.token=''
      --NotebookApp.password=''
      
    volumes:
      - ../notebooks:/app/notebooks
      - nvidia_models:/app/models
      - nvidia_cache:/app/cache
      
    ports:
      - "8888:8888"
      
    networks:
      - ethervox-network
