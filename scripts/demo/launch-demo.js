/**
 * Simple Node.js launcher for EthervoxAI Windows Desktop Demo
 * This handles the demo initialization and provides better error handling
 */

const { exec } = require('child_process');
const { promisify } = require('util');
const fs = require('fs');
const execAsync = promisify(exec);

/**
 * Check audio capabilities with platform-specific detection
 */
async function checkAudioCapabilities() {
  const status = {
    microphone: 'âŒ',
    speaker: 'âŒ', 
    wav: 'âŒ',
    tts: 'âŒ',
    platform: 'generic'
  };
  
  // Check basic Node.js packages
  try { require('mic'); status.microphone = 'âœ…'; } catch(e) { status.microphone = 'âŒ'; }
  try { require('speaker'); status.speaker = 'âœ…'; } catch(e) { status.speaker = 'âŒ'; }
  try { require('wav'); status.wav = 'âœ…'; } catch(e) { status.wav = 'âŒ'; }
  try { require('say'); status.tts = 'âœ…'; } catch(e) { status.tts = 'âŒ'; }
  
  // Detect Raspberry Pi
  if (process.platform === 'linux' && process.arch === 'arm64') {
    try {
      if (fs.existsSync('/proc/device-tree/model')) {
        const model = fs.readFileSync('/proc/device-tree/model', 'utf8');
        if (model.includes('Raspberry Pi')) {
          status.platform = 'raspberry-pi';
          
          // Check Raspberry Pi specific TTS engines
          try {
            await execAsync('which espeak');
            status.espeak = 'âœ…';
          } catch(e) { status.espeak = 'âŒ'; }
          
          try {
            await execAsync('which pico2wave');
            status.pico2wave = 'âœ…';
          } catch(e) { status.pico2wave = 'âŒ'; }
          
          try {
            await execAsync('which festival');
            status.festival = 'âœ…';
          } catch(e) { status.festival = 'âŒ'; }
          
          try {
            await execAsync('which aplay');
            status.alsa = 'âœ…';
          } catch(e) { status.alsa = 'âŒ'; }
          
          // Check for Bluetooth audio
          try {
            const { stdout } = await execAsync('pactl list sinks short');
            if (stdout.includes('bluez') || stdout.includes('bluetooth')) {
              status.bluetooth = 'âœ…';
            } else {
              status.bluetooth = 'âŒ';
            }
          } catch(e) { status.bluetooth = 'âŒ'; }
          
          // Override speaker status if we have working TTS engines
          if (status.espeak === 'âœ…' || status.pico2wave === 'âœ…' || status.festival === 'âœ…') {
            status.speaker = 'âœ… (TTS)';
            status.tts = 'âœ…';
          }
        }
      }
    } catch(e) {
      // Not a Raspberry Pi or can't detect
    }
  }
  
  return status;
}

console.log('ğŸš€ EthervoxAI Cross-Platform Demo');
console.log('===================================');
console.log();

async function runDemo() {
  try {
    console.log('Loading demo modules...');
    
    // Load the WindowsDesktopDemo class
    const { WindowsDesktopDemo } = require('../../dist/demo/windows-desktop');
    
    console.log('âœ… Demo modules loaded successfully');
    console.log();
    
    // Create and initialize the demo
    const demo = new WindowsDesktopDemo();
    
    console.log('ğŸ”§ Initializing demo...');
    await demo.initialize();
    
    console.log();
    console.log('=====================================');
    console.log('Commands available during demo:');
    console.log('  start  - Start voice listening');
    console.log('  stop   - Stop voice listening');
    console.log('  status - Show current status');
    console.log('  quit   - Exit application');
    console.log('=====================================');
    console.log();
    
    // Set up command line interface
    const readline = require('readline');
    const rl = readline.createInterface({
      input: process.stdin,
      output: process.stdout,
      prompt: 'EthervoxAI> '
    });
    
    rl.prompt();
    
    rl.on('line', async (input) => {
      const command = input.trim().toLowerCase();
      
      switch (command) {
        case 'start':
          console.log('ğŸ¤ Starting voice listening...');
          try {
            await demo.startListening();
            console.log('âœ… Voice listening started');
          } catch (error) {
            console.log('âš ï¸  Using simulated audio:', error.message);
          }
          break;
          
        case 'stop':
          console.log('ğŸ›‘ Stopping voice listening...');
          await demo.stopListening();
          console.log('âœ… Voice listening stopped');
          break;
          
        case 'status':
          console.log('ğŸ“Š Current status:');
          console.log('  - Listening:', demo.isListening ? 'âœ…' : 'âŒ');
          console.log('  - Processing:', demo.isProcessing ? 'âœ…' : 'âŒ');
          
          // Check audio library status with platform-specific detection
          const audioStatus = await checkAudioCapabilities();
          
          console.log('  - Audio Libraries:');
          console.log(`    â€¢ Microphone (mic): ${audioStatus.microphone}`);
          console.log(`    â€¢ Speaker output: ${audioStatus.speaker}`);
          console.log(`    â€¢ WAV processing: ${audioStatus.wav}`);
          console.log(`    â€¢ Text-to-Speech: ${audioStatus.tts}`);
          
          if (audioStatus.platform === 'raspberry-pi') {
            console.log('  ğŸ“ Raspberry Pi audio engines:');
            console.log(`    â€¢ eSpeak: ${audioStatus.espeak}`);
            console.log(`    â€¢ Pico2Wave: ${audioStatus.pico2wave}`);
            console.log(`    â€¢ Festival: ${audioStatus.festival}`);
            console.log(`    â€¢ ALSA/PulseAudio: ${audioStatus.alsa}`);
            
            if (audioStatus.bluetooth) {
              console.log(`    â€¢ Bluetooth Audio: ${audioStatus.bluetooth}`);
            }
          }
          
          if (audioStatus.speaker === 'âŒ' && audioStatus.platform !== 'raspberry-pi') {
            console.log('  âš ï¸  Audio output simulated (speaker package not available)');
            console.log('     This is common on ARM64 Windows systems.');
          }
          
          console.log(`  - System: ${process.platform} ${process.arch}, Node.js ${process.version}`);
          break;
          
        case 'quit':
        case 'exit':
          console.log('ğŸ‘‹ Goodbye!');
          process.exit(0);
          break;
          
        case 'help':
          console.log('Available commands: start, stop, status, quit, help');
          break;
          
        default:
          if (command) {
            console.log(`â“ Unknown command: ${command}. Type 'help' for available commands.`);
          }
          break;
      }
      
      rl.prompt();
    });
    
    rl.on('close', () => {
      console.log('ğŸ‘‹ Demo ended.');
      process.exit(0);
    });
    
  } catch (error) {
    console.error('âŒ Failed to start demo:', error.message);
    console.error();
    console.error('This might be due to:');
    console.error('1. Missing dependencies - run: npm install');
    console.error('2. Build not completed - run: npm run build');
    console.error('3. Audio libraries not installed (optional)');
    console.error();
    console.error('For basic demo functionality, only the core dependencies are required.');
    console.error('Audio features will be simulated if audio libraries are not available.');
    process.exit(1);
  }
}

// Handle uncaught exceptions gracefully
process.on('uncaughtException', (error) => {
  console.error('âŒ Unexpected error:', error.message);
  process.exit(1);
});

process.on('unhandledRejection', (reason, promise) => {
  console.error('âŒ Unhandled promise rejection:', reason);
  process.exit(1);
});

// Run the demo
runDemo();
